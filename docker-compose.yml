#-------------------------------------------------------------------------------------------------------
#                                                                                                      |
#                                           JCORE COMPOSE                                              |
#                                     (Cloudflare DNS Challenge)                                       |
#-------------------------------------------------------------------------------------------------------

version: '3.9'

services:
    
  nginx-proxy-manager:
    image: jc21/nginx-proxy-manager:2.12.3
    restart: unless-stopped
    networks:
      - jcore_proxy
    ports: 
      - "81:81"      # NPM Admin Interface
      - "443:443"    # HTTPS only
    environment:
      - CF_API_EMAIL=marco@3cubed.vc
      - CF_API_KEY=d3e09e987a02fd0fd3eeae182b09224f9bde5
      - DISABLE_IPV6=true
      - DB_SQLITE_FILE=/data/database.sqlite
    volumes:
      - /mnt/docker-data/jcore/nginx-proxy-manager:/data
      - /etc/letsencrypt:/etc/letsencrypt
    dns:
      - 1.1.1.1
      - 8.8.8.8

  mariadb:
    container_name: jcore_mariadb
    image: mariadb:10.11
    networks:
      - jcore_proxy
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: "mb415%"
      MYSQL_DATABASE: "JCORE"
      MYSQL_USER: "mbxxvii"
      MYSQL_PASSWORD: "6wk44!ez#MS2Qhhw"
    volumes:
      - ./mariadb:/var/lib/mysql
    expose:
      - "3306"

  influxdb:
    container_name: jcore_influxdb
    image: influxdb:2.7
    networks:
      - jcore_proxy
    restart: unless-stopped
    expose:
      - "8086"
    volumes:
      - influxdb-storage:/var/lib/influxdb2
      - influxdb-config:/etc/influxdb2
    environment:
      DOCKER_INFLUXDB_INIT_MODE: "setup"
      DOCKER_INFLUXDB_INIT_USERNAME: "mbxxvii"
      DOCKER_INFLUXDB_INIT_PASSWORD: "6wk44!ez#MS2Qhhw"
      DOCKER_INFLUXDB_INIT_ORG: "jia"
      DOCKER_INFLUXDB_INIT_BUCKET: "jcore"
      DOCKER_INFLUXDB_INIT_RETENTION: "90d"

  prometheus:
    container_name: jcore_prometheus
    image: prom/prometheus:latest
    restart: unless-stopped
    networks:
      - jcore_proxy   
    expose:
      - "9090"
    volumes:
      - /mnt/docker-data/jcore/config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - /mnt/docker-data/jcore/config/prometheus/ha.token:/etc/prometheus/ha.token:ro

  jia-loki:
    container_name: jcore_loki
    image: grafana/loki:2.9.1
    user: "0:0"
    restart: unless-stopped
    command:
      - "-config.file=/etc/loki/config.yaml"
      - "-log.level=debug"
      - "-target=all"
      - "-config.expand-env=true"
    networks:
      - jcore_proxy   
    expose:
      - "3100"
      - "9095"
    volumes:
      - /mnt/docker-data/homeassistant/loki/config/config.yaml:/etc/loki/config.yaml
      - /mnt/docker-data/homeassistant/loki/data:/loki/data
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  cadvisor:
    container_name: jcore_cadvisor
    image: gcr.io/cadvisor/cadvisor:latest
    restart: unless-stopped
    networks:
      - jcore_proxy    
    expose:
      - "8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro

  homeassistant:
    container_name: jcore_ha
    image: homeassistant/home-assistant:stable
    restart: unless-stopped
    networks:
      - jcore_proxy   
    expose:
      - "8123"
    environment:
      TZ: "Etc/UTC"
    volumes:
      - /mnt/docker-data/jcore/config:/config
      - /etc/localtime:/etc/localtime:ro
    depends_on:
      - mariadb
      - influxdb
      - wyoming-piper
      - wyoming-whisper
      - wyoming-openwakeword

  esphome:
    container_name: jcore_esp
    image: ghcr.io/esphome/esphome:2025.5.0b4
    privileged: true
    restart: unless-stopped
    environment:
      TZ: "Etc/UTC"
    volumes:
      - ./esphome:/config
      - /etc/localtime:/etc/localtime:ro
    networks:
      - jcore_proxy   
    expose:
      - "6052"
    command: >
      dashboard /config
      --address 0.0.0.0
      --port 6052
      --username mbxxvii
      --password mb415%

  mosquitto:
    container_name: jcore_mosquitto
    image: eclipse-mosquitto:latest
    restart: unless-stopped
    networks:
      - jcore_proxy    
    ports:
      - "1883:1883"    # MQTT 
      - "9002:9001"    # WebSocket
    volumes:
      - ./mosquitto/config:/mosquitto/config
      - ./mosquitto/data:/mosquitto/data
      - ./mosquitto/log:/mosquitto/log

  watchtower:
    container_name: jcore_watchtower
    image: containrrr/watchtower:latest
    restart: unless-stopped
    command: --cleanup --interval 3600
    networks:
      - jcore_proxy    
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

#-------------------------------------------------------------------------------------------------------
#                                         WYOMING VOICE SERVICES                                       |
#-------------------------------------------------------------------------------------------------------

  wyoming-piper:
    container_name: jcore_wyoming
    image: rhasspy/wyoming-piper:latest
    restart: unless-stopped
    networks:
      - jcore_proxy    
    expose:
      - "10200"
    volumes:
      - ./piper-data:/data
    command:
      - --voice
      - en_US-lessac-medium
      - --uri
      - tcp://0.0.0.0:10200
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:10200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  wyoming-whisper:
    container_name: jcore_whisper
    image: rhasspy/wyoming-faster-whisper:latest
    restart: unless-stopped
    networks:
      - jcore_proxy
    expose:
      - "10300"
    volumes:
      - ./whisper-data:/data
      - ./whisper-models:/models
    command:
      - --model
      - base
      - --language
      - en
      - --uri
      - tcp://0.0.0.0:10300
      - --data-dir
      - /data
      - --download-dir
      - /models
      - --device
      - cpu
      - --compute-type
      - int8
      - --beam-size
      - "1"
      - --initial-prompt
      - "This is a voice assistant for home automation."
    environment:
      - WHISPER_CACHE_DIR=/models
      - FASTER_WHISPER_CACHE_DIR=/models
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:10300 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  wyoming-openwakeword:
    container_name: jcore_openwakeword
    image: rhasspy/wyoming-openwakeword:latest
    restart: unless-stopped
    networks:
      - jcore_proxy
    expose:
      - "10400"
    volumes:
      - ./openwakeword-data:/data
      - ./openwakeword-models:/models
    command:
      - --uri
      - tcp://0.0.0.0:10400
      - --preload-model
      - alexa
      - --preload-model
      - hey_jarvis
      - --preload-model
      - ok_nabu
      - --custom-model-dir
      - /models
      - --threshold
      - "0.5"
      - --trigger-level
      - "1"
      - --debug
    environment:
      - OPENWAKEWORD_CACHE_DIR=/models
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:10400 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  #  Wyoming Satellite (additional microphone support)
#  wyoming-satellite:
#    container_name: jcore_satellite
#    image: rhasspy/wyoming-satellite:latest
#    restart: unless-stopped
#    networks:
#      - jcore_proxy
#    expose:
#      - "10500"
#    volumes:
#      - ./satellite-data:/data
#    command:
#      - --uri
#      - tcp://0.0.0.0:10500
#      - --mic-command
#      - "arecord -r 16000 -c 1 -f S16_LE -t raw"
#      - --snd-command
#      - "aplay -r 16000 -c 1 -f S16_LE -t raw"
#      - --debug
#    depends_on:
#      - wyoming-whisper
#      - wyoming-openwakeword
#      - wyoming-piper
#    healthcheck:
#      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:10500 || exit 1"]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#    deploy:
#      resources:
#        limits:
#          memory: 256M
#        reservations:
#          memory: 128M
#    profiles:
#      - optional

#-------------------------------------------------------------------------------------------------------
#                                           UTILITY SERVICES                                           |
#-------------------------------------------------------------------------------------------------------

  terminal:
    container_name: jcore_terminal
    image: tsl0922/ttyd:latest
    restart: unless-stopped
    networks:
      - jcore_proxy    
    expose:
      - "7681"
    volumes:
      - ./config:/config
    command:
      - ttyd
      - -p
      - "7681"
      - bash

  filebrowser:
    container_name: jcore_filebrowser
    image: filebrowser/filebrowser:latest
    restart: unless-stopped
    networks:
      - jcore_proxy
    expose:
      - "80"
    environment:
      FB_BASEURL: "/"
      HOME: "/config"
    volumes:
      - /mnt/docker-data/jcore/config:/srv
      - /mnt/docker-data/jcore/filebrowser_config:/config
    command:
      - --root
      - /srv

  uptime-kuma:
    container_name: jcore_kuma
    image: louislam/uptime-kuma:1.23.15-alpine
    restart: unless-stopped
    networks:
      - jcore_proxy    
    expose:
      - "3001"
    volumes:
      - uptime-kuma-data:/app/data

  grafana-renderer:
    container_name: jcore_grafana_rdr
    image: grafana/grafana-image-renderer:latest
    restart: unless-stopped
    networks:
      - jcore_proxy     
    expose:
      - "8081"

  grafana:
    container_name: jcore_grafana
    image: grafana/grafana:latest
    restart: unless-stopped
    networks:
      - jcore_proxy    
    expose:
      - "3000"
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana-provisioning:/etc/grafana/provisioning
    depends_on:
      - influxdb
    environment:
      GF_SECURITY_ADMIN_USER: "mbxxvii"
      GF_SECURITY_ADMIN_PASSWORD: "mb415%"
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_DOMAIN: "grafana.dreammachine.casa"
      GF_SERVER_ROOT_URL: "https://grafana.dreammachine.casa"
      GF_SERVER_SERVE_FROM_SUB_PATH: "false"
      GF_RENDERING_SERVER_URL: "http://jcore_grafana_rdr:8081"
      GF_SECURITY_ALLOW_EMBEDDING: "true"
      GF_COOKIE_SAMESITE: "none"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_NAME: "Main Org."
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Viewer"

networks:
  jcore_proxy:
    driver: bridge

volumes:
  influxdb-storage:
  influxdb-config:
  grafana-storage:
  uptime-kuma-data:
